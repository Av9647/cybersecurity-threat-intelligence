#!/usr/bin/env python3
"""
Diff vendor-product combos by:
  • any change in their CVE list (add/remove)
  • or any CVE metadata update (lastModifiedDate or publishedDate)
since the build from at least BUFFER_DAYS ago,
then send changed combos to SQS in batches of 10.
If no build older than BUFFER_DAYS exists, this script errors.
"""
import os
import json
from datetime import datetime, timezone, timedelta
from pymongo import MongoClient
import boto3
from itertools import islice

# ─── Configuration ──────────────────────────────────────────────────────────
MONGO_URI   = os.getenv("MONGO_URI", "mongodb://mongo:27017/")
DB_NAME     = os.getenv("DB_NAME",   "cvedb")
QUEUE_URL   = os.getenv(
    "DELTA_QUEUE_URL",
    "https://sqs.us-east-2.amazonaws.com/692859941232/cve_ingestion_vendor_product_sqs"
)
BUFFER_DAYS = int(os.getenv("BUFFER_DAYS", "3"))
BATCH_SIZE  = 10   # SQS max

MAP_NVD     = "map_vendor_product_nvd"
MAP_CVELIST = "map_vendor_product_cvelistv5"
META_COLL   = "map_build_meta"
CVE_COLL    = "cves"
# ─────────────────────────────────────────────────────────────────────────────

client = MongoClient(MONGO_URI)
db     = client[DB_NAME]
sqs    = boto3.client("sqs")


def get_newest_ts(tag: str) -> datetime:
    doc = db[META_COLL].find_one(
        {"collection": tag}, sort=[("ts", -1)]
    )
    if not doc:
        raise RuntimeError(f"No builds found for '{tag}'")
    return doc["ts"]


def get_baseline_ts(tag: str, buffer_days: int = BUFFER_DAYS) -> datetime:
    cutoff = datetime.now(timezone.utc) - timedelta(days=buffer_days)
    doc = db[META_COLL].find_one(
        {"collection": tag, "ts": {"$lte": cutoff}},
        sort=[("ts", -1)]
    )
    if not doc:
        raise RuntimeError(
            f"No build older than {buffer_days} days for '{tag}'. "
            "Please reduce your BUFFER_DAYS and try again."
        )
    return doc["ts"]


new_nvd_ts  = get_newest_ts("nvd_ts")
prev_nvd_ts = get_baseline_ts("nvd_ts")

new_cl_ts   = get_newest_ts("cvelistv5_ts")
prev_cl_ts  = get_baseline_ts("cvelistv5_ts")

print(f"Diffing NVD map:      {prev_nvd_ts} → {new_nvd_ts}")
print(f"Diffing CVE-List map: {prev_cl_ts} → {new_cl_ts}")

# 2) CVEs whose metadata changed since the earlier baseline
baseline = min(prev_nvd_ts, prev_cl_ts)
changed_cves = [
    c["id"]
    for c in db[CVE_COLL].find(
        {"$or": [
            {"lastModifiedDate": {"$gt": baseline}},
            {"publishedDate":    {"$gt": baseline}}
        ]},
        {"_id":0, "id":1}
    )
]
print(f" → {len(changed_cves):,} CVEs modified since {baseline.isoformat()}")

# 3) Build the diff pipeline
pipeline = [
    # start with new NVD entries
    {"$match": {"_build_ts": new_nvd_ts}},
    # pull in new CVE-List combos
    {"$unionWith": {
        "coll": MAP_CVELIST,
        "pipeline": [{"$match": {"_build_ts": new_cl_ts}}]
    }},
    # lookup their old CVE lists
    {"$lookup": {
        "from": MAP_NVD,
        "let": {"id": "$_id"},
        "pipeline": [
            {"$match": {"$expr": {
                "$and": [
                    {"$eq": ["$_id", "$$id"]},
                    {"$eq": ["$_build_ts", prev_nvd_ts]}
                ]
            }}},
            {"$project": {"cves": 1}}
        ],
        "as": "old_nvd"
    }},
    {"$lookup": {
        "from": MAP_CVELIST,
        "let": {"id": "$_id"},
        "pipeline": [
            {"$match": {"$expr": {
                "$and": [
                    {"$eq": ["$_id", "$$id"]},
                    {"$eq": ["$_build_ts", prev_cl_ts]}
                ]
            }}},
            {"$project": {"cves": 1}}
        ],
        "as": "old_cl"
    }},
    # keep combos whose CVE array changed
    {"$match": {"$expr": {
        "$or": [
            {"$gt": [
                {"$size": {"$setDifference": [
                    "$cves", {"$arrayElemAt": ["$old_nvd.cves", 0]}
                ]}},
                0
            ]},
            {"$gt": [
                {"$size": {"$setDifference": [
                    "$cves", {"$arrayElemAt": ["$old_cl.cves", 0]}
                ]}},
                0
            ]}
        ]
    }}},
    # also any combo that contains one of the changed CVEs
    {"$unionWith": {
        "coll": MAP_NVD,
        "pipeline":[
            {"$match": {"cves": {"$in": changed_cves}}},
            {"$project":{"_id":1}}
        ]
    }},
    {"$unionWith": {
        "coll": MAP_CVELIST,
        "pipeline":[
            {"$match": {"cves": {"$in": changed_cves}}},
            {"$project":{"_id":1}}
        ]
    }},
    # dedupe and project out vendor/product
    {"$group": {"_id":"$_id"}},
    {"$project": {
        "_id":     0,
        "vendor":  "$_id.vendor",
        "product": "$_id.product"
    }}
]

# batch helper
def batched(it, n):
    it = iter(it)
    while True:
        batch = list(islice(it, n))
        if not batch:
            return
        yield batch

# 4) run & push to SQS
cursor = db[MAP_NVD].aggregate(pipeline, allowDiskUse=True)
run_ts = datetime.now(timezone.utc).isoformat()
sent   = 0

for batch in batched(cursor, BATCH_SIZE):
    entries = [{
        "Id":          f"{d['vendor']}#{d['product']}",
        "MessageBody": json.dumps({
            "vendor":             d["vendor"],
            "product":            d["product"],
            "ingestionTimestamp": run_ts
        }, ensure_ascii=False)
    } for d in batch]
    resp = sqs.send_message_batch(QueueUrl=QUEUE_URL, Entries=entries)
    if resp.get("FailedPutCount", 0):
        failed = [f["Id"] for f in resp["Failed"]]
        raise RuntimeError(f"SQS batch send failed for IDs: {failed}")
    sent += len(entries)

print(f"✔ Diff complete; sent {sent} messages to SQS.")
